version: '3.8'

services:
  # Detector - Hybrid detection service with CUDA support
  # Runs independently while web UI runs on host
  detector:
    build:
      context: .
      dockerfile: Dockerfile.detector
    container_name: toddler-tracker-detector
    volumes:
      # Mount host databases (read-write for detector)
      - ./yard.db:/app/yard.db
      - ./matches.db:/app/matches.db
      - ./config.db:/app/config.db
      # Model cache (persist downloaded models)
      - ~/.cache/torch:/root/.cache/torch
    # Use host network to access Frigate and share databases with host app
    network_mode: host
    restart: unless-stopped
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - PYTHONUNBUFFERED=1
      - FRIGATE_URL=http://localhost:5000
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "python3", "-c", "import os; assert os.path.exists('matches.db')"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s
